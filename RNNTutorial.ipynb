{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = 20000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000,)\n",
      "y_train shape: (25000,)\n",
      "X_test shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns number of words in string \n",
    "def countWords(string):\n",
    "    state = False \n",
    "    wc = 0\n",
    "  \n",
    "    # Scan all characters one by one \n",
    "    for i in range(len(string)): \n",
    "  \n",
    "        # If next character is a separator,  \n",
    "        # set the state as OUT \n",
    "        if (string[i] == ' ' or string[i] == '\\n' or\n",
    "            string[i] == '\\t'): \n",
    "            state = False \n",
    "\n",
    "        elif state == False: \n",
    "            state = True \n",
    "            wc += 1\n",
    "  \n",
    "    # Return the number of words \n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "number of words: 189\n"
     ]
    }
   ],
   "source": [
    "ran_num = 1\n",
    "print(X_train[ran_num])\n",
    "print(\"number of words:\", len(X_train[ran_num]))\n",
    "class_names = [\"negative review\", \"positive review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer imdb dataset from integer to word and tutorial website is below  \n",
    "https://www.kaggle.com/vikramtiwari/tensorflow-high-level-apis-imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their UNK sickening that men actually wore them and the music is just UNK trash that plays over and over again in almost every scene there is trashy music boobs and UNK taking away bodies and the gym still doesn't close for UNK all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "movie review: negative review\n",
      "number of words: 189\n"
     ]
    }
   ],
   "source": [
    "# dictionary that hashes words to their integer\n",
    "word_to_integer = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# print out the first ten keys and values in the dictionary\n",
    "# print(list(word_to_integer.keys())[0:10])\n",
    "# print(list(word_to_integer.values())[0:10])\n",
    "\n",
    "integer_to_word = dict([(value, key) for (key, value) in word_to_integer.items()])\n",
    "\n",
    "# demonstrate how to find the word from an integer\n",
    "# print(integer_to_word[1])\n",
    "# print(integer_to_word[14-3])\n",
    "\n",
    "# we need to subtract 3 from the indices because 0 is 'padding', 1 is 'start of sequence' and 2 is 'unknown'\n",
    "decoded_review = ' '.join([integer_to_word.get(i - 3, 'UNK') for i in X_train[ran_num]])\n",
    "print(decoded_review)\n",
    "print(\"movie review:\", class_names[y_train[ran_num]])\n",
    "print(\"number of words:\", countWords(decoded_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their UNK sickening that men actually wore them and the music is just UNK trash that plays over and over again in almost every scene there is trashy music boobs and UNK taking away bodies and the gym still doesn't close for UNK all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "movie review: negative review\n",
      "number of words: 100\n"
     ]
    }
   ],
   "source": [
    "decoded_review = ' '.join([integer_to_word.get(i - 3, 'UNK') for i in X_train[ran_num]])\n",
    "print(decoded_review)\n",
    "print(\"movie review:\", class_names[y_train[ran_num]])\n",
    "print(\"number of words:\", countWords(decoded_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=number_of_words, output_dim=128, input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.LSTM(units=128, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(3,))\n",
    "Model = tf.keras.layers.Embedding(input_dim=5, output_dim=2)(inputs)\n",
    "Model = tf.keras.layers.LSTM(units=3, activation='tanh')(Model)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(Model)\n",
    "Model = tf.keras.Model(inputs, outputs)\n",
    "Model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 3, 2)              10        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 3)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer\n",
    "[visualize] https://ronxin.github.io/wevi/  \n",
    "[reference] http://frankchen.xyz/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/  \n",
    "[reference] https://www.quora.com/How-does-word2vec-work-Can-someone-walk-through-a-specific-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "[reference] https://blog.csdn.net/Jerr__y/article/details/58598296  \n",
    "[reference] https://kknews.cc/zh-tw/code/l4yya2e.html  \n",
    "[youtube] https://www.youtube.com/watch?v=xCGidAeyS4M  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.4533 - accuracy: 0.7864\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 30s 1ms/sample - loss: 0.2911 - accuracy: 0.8830\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 29s 1ms/sample - loss: 0.2326 - accuracy: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f104a04ad30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acurracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8402799963951111\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {}\".format(test_acurracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ran_num = random.randint(0,24999)\n",
    "test_data = tf.expand_dims(X_test[ran_num], axis=0)\n",
    "predict = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data: 23568\n",
      "predict: tf.Tensor(0.022317527, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.squeeze(predict)\n",
    "print(\"test_data:\", ran_num)\n",
    "print(\"predict:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = lambda v: 1 if prediction > 0.5 else 0\n",
    "prediction_value = review(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: negative review\n",
      "predict negative review\n"
     ]
    }
   ],
   "source": [
    "label = class_names[y_test[ran_num]]\n",
    "label_prediction = class_names[prediction_value]\n",
    "print(\"label:\", label)\n",
    "print(\"predict\", label_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to complete so many UNK puzzles in a day she spends an awful lot of time standing around UNK and not doing puzzles i believe there is more walking shown in the movie than her work on these puzzles also while i understand the point of showing so much scenery there is simply far too much of it the movie is incredibly boring and unfocused it's not worth buying renting watching on television or viewing in any conceivable way i lost interest so quickly that i'm not sure why i sat through the entire film in the first place\n"
     ]
    }
   ],
   "source": [
    "decoded_review = ' '.join([integer_to_word.get(i - 3, 'UNK') for i in X_test[ran_num]])\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
